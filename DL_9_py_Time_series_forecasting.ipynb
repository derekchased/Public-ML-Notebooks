{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook adapts the Tensorflow tutorial on [Time series forecasting](https://www.tensorflow.org/tutorials/structured_data/time_series) to data generated from a model for epidemic processes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Imports and setup\n",
    "2. Load and prepare the generated data\n",
    "3. Baseline forecasting\n",
    "4. Univariate LSTM based forecasting\n",
    "5. Multivariate LSTM based forecasting - Single Step\n",
    "6. Multivariate LSTM based forecasting - Multiple Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (8, 6)\n",
    "mpl.rcParams['axes.grid'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare the generated data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load data from the ODE model introduced in the notebook \"Probability and Information Theory\". For each of the 150 virtuel outbreaks (randomized and with different model parameters), we have time series (with 500 steps) for four the variables \"Susceptible\", \"Infected\", \"Recovered\", and \"Deceased\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "      <th>500</th>\n",
       "      <th>501</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.287149</td>\n",
       "      <td>103.541223</td>\n",
       "      <td>95.879814</td>\n",
       "      <td>96.354848</td>\n",
       "      <td>96.980932</td>\n",
       "      <td>97.855310</td>\n",
       "      <td>98.940537</td>\n",
       "      <td>100.187494</td>\n",
       "      <td>98.265709</td>\n",
       "      <td>95.307794</td>\n",
       "      <td>...</td>\n",
       "      <td>4.925236</td>\n",
       "      <td>4.922108</td>\n",
       "      <td>4.918981</td>\n",
       "      <td>4.915853</td>\n",
       "      <td>4.912726</td>\n",
       "      <td>4.950240</td>\n",
       "      <td>4.995291</td>\n",
       "      <td>5.040342</td>\n",
       "      <td>5.085393</td>\n",
       "      <td>5.130445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.993774</td>\n",
       "      <td>1.017558</td>\n",
       "      <td>1.070030</td>\n",
       "      <td>1.116168</td>\n",
       "      <td>1.142078</td>\n",
       "      <td>1.134735</td>\n",
       "      <td>1.182418</td>\n",
       "      <td>1.272310</td>\n",
       "      <td>1.356565</td>\n",
       "      <td>1.438978</td>\n",
       "      <td>...</td>\n",
       "      <td>0.391775</td>\n",
       "      <td>0.384359</td>\n",
       "      <td>0.376942</td>\n",
       "      <td>0.369526</td>\n",
       "      <td>0.362109</td>\n",
       "      <td>0.356669</td>\n",
       "      <td>0.351595</td>\n",
       "      <td>0.346521</td>\n",
       "      <td>0.341447</td>\n",
       "      <td>0.336374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017741</td>\n",
       "      <td>0.036585</td>\n",
       "      <td>0.054735</td>\n",
       "      <td>0.074266</td>\n",
       "      <td>0.096065</td>\n",
       "      <td>0.117691</td>\n",
       "      <td>0.139184</td>\n",
       "      <td>0.163615</td>\n",
       "      <td>0.189006</td>\n",
       "      <td>...</td>\n",
       "      <td>97.247764</td>\n",
       "      <td>96.062916</td>\n",
       "      <td>94.878068</td>\n",
       "      <td>93.693219</td>\n",
       "      <td>92.508371</td>\n",
       "      <td>92.617122</td>\n",
       "      <td>92.965783</td>\n",
       "      <td>93.314443</td>\n",
       "      <td>93.663103</td>\n",
       "      <td>94.011764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>0.000562</td>\n",
       "      <td>0.000757</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>0.001160</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>0.001635</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>...</td>\n",
       "      <td>0.947347</td>\n",
       "      <td>0.950713</td>\n",
       "      <td>0.954079</td>\n",
       "      <td>0.957445</td>\n",
       "      <td>0.960811</td>\n",
       "      <td>0.959320</td>\n",
       "      <td>0.956929</td>\n",
       "      <td>0.954537</td>\n",
       "      <td>0.952146</td>\n",
       "      <td>0.949755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>103.489688</td>\n",
       "      <td>100.282780</td>\n",
       "      <td>96.634270</td>\n",
       "      <td>98.532514</td>\n",
       "      <td>99.089272</td>\n",
       "      <td>97.440900</td>\n",
       "      <td>98.416534</td>\n",
       "      <td>101.404903</td>\n",
       "      <td>100.480758</td>\n",
       "      <td>98.277282</td>\n",
       "      <td>...</td>\n",
       "      <td>2.071958</td>\n",
       "      <td>2.064501</td>\n",
       "      <td>2.072213</td>\n",
       "      <td>2.090890</td>\n",
       "      <td>2.109567</td>\n",
       "      <td>2.128244</td>\n",
       "      <td>2.146921</td>\n",
       "      <td>2.165597</td>\n",
       "      <td>2.184274</td>\n",
       "      <td>2.202951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            1           2          3          4          5          6  \\\n",
       "0  100.287149  103.541223  95.879814  96.354848  96.980932  97.855310   \n",
       "1    0.993774    1.017558   1.070030   1.116168   1.142078   1.134735   \n",
       "2    0.000000    0.017741   0.036585   0.054735   0.074266   0.096065   \n",
       "3    0.000000    0.000178   0.000364   0.000562   0.000757   0.000947   \n",
       "4  103.489688  100.282780  96.634270  98.532514  99.089272  97.440900   \n",
       "\n",
       "           7           8           9         10  ...        492        493  \\\n",
       "0  98.940537  100.187494   98.265709  95.307794  ...   4.925236   4.922108   \n",
       "1   1.182418    1.272310    1.356565   1.438978  ...   0.391775   0.384359   \n",
       "2   0.117691    0.139184    0.163615   0.189006  ...  97.247764  96.062916   \n",
       "3   0.001160    0.001389    0.001635   0.001887  ...   0.947347   0.950713   \n",
       "4  98.416534  101.404903  100.480758  98.277282  ...   2.071958   2.064501   \n",
       "\n",
       "         494        495        496        497        498        499  \\\n",
       "0   4.918981   4.915853   4.912726   4.950240   4.995291   5.040342   \n",
       "1   0.376942   0.369526   0.362109   0.356669   0.351595   0.346521   \n",
       "2  94.878068  93.693219  92.508371  92.617122  92.965783  93.314443   \n",
       "3   0.954079   0.957445   0.960811   0.959320   0.956929   0.954537   \n",
       "4   2.072213   2.090890   2.109567   2.128244   2.146921   2.165597   \n",
       "\n",
       "         500        501  \n",
       "0   5.085393   5.130445  \n",
       "1   0.341447   0.336374  \n",
       "2  93.663103  94.011764  \n",
       "3   0.952146   0.949755  \n",
       "4   2.184274   2.202951  \n",
       "\n",
       "[5 rows x 501 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_path = \"./data/epidemic_process_raw_data.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "      <th>500</th>\n",
       "      <th>501</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.287149</td>\n",
       "      <td>103.541223</td>\n",
       "      <td>95.879814</td>\n",
       "      <td>96.354848</td>\n",
       "      <td>96.980932</td>\n",
       "      <td>97.855310</td>\n",
       "      <td>98.940537</td>\n",
       "      <td>100.187494</td>\n",
       "      <td>98.265709</td>\n",
       "      <td>95.307794</td>\n",
       "      <td>...</td>\n",
       "      <td>4.925236</td>\n",
       "      <td>4.922108</td>\n",
       "      <td>4.918981</td>\n",
       "      <td>4.915853</td>\n",
       "      <td>4.912726</td>\n",
       "      <td>4.950240</td>\n",
       "      <td>4.995291</td>\n",
       "      <td>5.040342</td>\n",
       "      <td>5.085393</td>\n",
       "      <td>5.130445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>103.489688</td>\n",
       "      <td>100.282780</td>\n",
       "      <td>96.634270</td>\n",
       "      <td>98.532514</td>\n",
       "      <td>99.089272</td>\n",
       "      <td>97.440900</td>\n",
       "      <td>98.416534</td>\n",
       "      <td>101.404903</td>\n",
       "      <td>100.480758</td>\n",
       "      <td>98.277282</td>\n",
       "      <td>...</td>\n",
       "      <td>2.071958</td>\n",
       "      <td>2.064501</td>\n",
       "      <td>2.072213</td>\n",
       "      <td>2.090890</td>\n",
       "      <td>2.109567</td>\n",
       "      <td>2.128244</td>\n",
       "      <td>2.146921</td>\n",
       "      <td>2.165597</td>\n",
       "      <td>2.184274</td>\n",
       "      <td>2.202951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>101.527421</td>\n",
       "      <td>97.711732</td>\n",
       "      <td>96.168179</td>\n",
       "      <td>95.677962</td>\n",
       "      <td>95.575326</td>\n",
       "      <td>96.109792</td>\n",
       "      <td>96.943831</td>\n",
       "      <td>98.007655</td>\n",
       "      <td>98.132798</td>\n",
       "      <td>97.951008</td>\n",
       "      <td>...</td>\n",
       "      <td>48.629414</td>\n",
       "      <td>48.662862</td>\n",
       "      <td>48.696309</td>\n",
       "      <td>48.729757</td>\n",
       "      <td>48.763204</td>\n",
       "      <td>48.796652</td>\n",
       "      <td>48.830099</td>\n",
       "      <td>48.863547</td>\n",
       "      <td>48.896994</td>\n",
       "      <td>48.930442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>101.061107</td>\n",
       "      <td>99.112815</td>\n",
       "      <td>106.651686</td>\n",
       "      <td>101.622904</td>\n",
       "      <td>97.726686</td>\n",
       "      <td>95.692173</td>\n",
       "      <td>97.438263</td>\n",
       "      <td>102.084252</td>\n",
       "      <td>101.831030</td>\n",
       "      <td>99.975843</td>\n",
       "      <td>...</td>\n",
       "      <td>3.890526</td>\n",
       "      <td>3.869629</td>\n",
       "      <td>3.894123</td>\n",
       "      <td>3.928628</td>\n",
       "      <td>3.963133</td>\n",
       "      <td>3.997638</td>\n",
       "      <td>4.032143</td>\n",
       "      <td>4.066648</td>\n",
       "      <td>4.101153</td>\n",
       "      <td>4.135658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>101.957189</td>\n",
       "      <td>101.898022</td>\n",
       "      <td>100.881113</td>\n",
       "      <td>99.892000</td>\n",
       "      <td>98.939878</td>\n",
       "      <td>98.048565</td>\n",
       "      <td>98.220024</td>\n",
       "      <td>99.206678</td>\n",
       "      <td>99.067041</td>\n",
       "      <td>98.559123</td>\n",
       "      <td>...</td>\n",
       "      <td>5.878943</td>\n",
       "      <td>5.910111</td>\n",
       "      <td>5.941279</td>\n",
       "      <td>5.959441</td>\n",
       "      <td>5.860292</td>\n",
       "      <td>5.761142</td>\n",
       "      <td>5.667567</td>\n",
       "      <td>5.680109</td>\n",
       "      <td>5.692651</td>\n",
       "      <td>5.705193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             1           2           3           4          5          6  \\\n",
       "0   100.287149  103.541223   95.879814   96.354848  96.980932  97.855310   \n",
       "4   103.489688  100.282780   96.634270   98.532514  99.089272  97.440900   \n",
       "8   101.527421   97.711732   96.168179   95.677962  95.575326  96.109792   \n",
       "12  101.061107   99.112815  106.651686  101.622904  97.726686  95.692173   \n",
       "16  101.957189  101.898022  100.881113   99.892000  98.939878  98.048565   \n",
       "\n",
       "            7           8           9         10  ...        492        493  \\\n",
       "0   98.940537  100.187494   98.265709  95.307794  ...   4.925236   4.922108   \n",
       "4   98.416534  101.404903  100.480758  98.277282  ...   2.071958   2.064501   \n",
       "8   96.943831   98.007655   98.132798  97.951008  ...  48.629414  48.662862   \n",
       "12  97.438263  102.084252  101.831030  99.975843  ...   3.890526   3.869629   \n",
       "16  98.220024   99.206678   99.067041  98.559123  ...   5.878943   5.910111   \n",
       "\n",
       "          494        495        496        497        498        499  \\\n",
       "0    4.918981   4.915853   4.912726   4.950240   4.995291   5.040342   \n",
       "4    2.072213   2.090890   2.109567   2.128244   2.146921   2.165597   \n",
       "8   48.696309  48.729757  48.763204  48.796652  48.830099  48.863547   \n",
       "12   3.894123   3.928628   3.963133   3.997638   4.032143   4.066648   \n",
       "16   5.941279   5.959441   5.860292   5.761142   5.667567   5.680109   \n",
       "\n",
       "          500        501  \n",
       "0    5.085393   5.130445  \n",
       "4    2.184274   2.202951  \n",
       "8   48.896994  48.930442  \n",
       "12   4.101153   4.135658  \n",
       "16   5.692651   5.705193  \n",
       "\n",
       "[5 rows x 501 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfSusceptible = df[df.index % 4 == 0]\n",
    "dfSusceptible.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "      <th>500</th>\n",
       "      <th>501</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.993774</td>\n",
       "      <td>1.017558</td>\n",
       "      <td>1.070030</td>\n",
       "      <td>1.116168</td>\n",
       "      <td>1.142078</td>\n",
       "      <td>1.134735</td>\n",
       "      <td>1.182418</td>\n",
       "      <td>1.272310</td>\n",
       "      <td>1.356565</td>\n",
       "      <td>1.438978</td>\n",
       "      <td>...</td>\n",
       "      <td>0.391775</td>\n",
       "      <td>0.384359</td>\n",
       "      <td>0.376942</td>\n",
       "      <td>0.369526</td>\n",
       "      <td>0.362109</td>\n",
       "      <td>0.356669</td>\n",
       "      <td>0.351595</td>\n",
       "      <td>0.346521</td>\n",
       "      <td>0.341447</td>\n",
       "      <td>0.336374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.021677</td>\n",
       "      <td>1.045410</td>\n",
       "      <td>1.120324</td>\n",
       "      <td>1.175914</td>\n",
       "      <td>1.236878</td>\n",
       "      <td>1.306676</td>\n",
       "      <td>1.387931</td>\n",
       "      <td>1.477973</td>\n",
       "      <td>1.549873</td>\n",
       "      <td>1.615840</td>\n",
       "      <td>...</td>\n",
       "      <td>0.172933</td>\n",
       "      <td>0.171653</td>\n",
       "      <td>0.169739</td>\n",
       "      <td>0.167366</td>\n",
       "      <td>0.164993</td>\n",
       "      <td>0.162620</td>\n",
       "      <td>0.160247</td>\n",
       "      <td>0.157874</td>\n",
       "      <td>0.155501</td>\n",
       "      <td>0.153128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.020043</td>\n",
       "      <td>1.011238</td>\n",
       "      <td>1.031122</td>\n",
       "      <td>1.048642</td>\n",
       "      <td>1.049479</td>\n",
       "      <td>1.022891</td>\n",
       "      <td>1.035862</td>\n",
       "      <td>1.079177</td>\n",
       "      <td>1.114531</td>\n",
       "      <td>1.147282</td>\n",
       "      <td>...</td>\n",
       "      <td>5.658505</td>\n",
       "      <td>5.625406</td>\n",
       "      <td>5.592308</td>\n",
       "      <td>5.559209</td>\n",
       "      <td>5.526111</td>\n",
       "      <td>5.493012</td>\n",
       "      <td>5.459914</td>\n",
       "      <td>5.426815</td>\n",
       "      <td>5.393717</td>\n",
       "      <td>5.360619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.035248</td>\n",
       "      <td>1.014189</td>\n",
       "      <td>1.133178</td>\n",
       "      <td>1.135622</td>\n",
       "      <td>1.157984</td>\n",
       "      <td>1.213088</td>\n",
       "      <td>1.281406</td>\n",
       "      <td>1.359858</td>\n",
       "      <td>1.423234</td>\n",
       "      <td>1.481680</td>\n",
       "      <td>...</td>\n",
       "      <td>0.297238</td>\n",
       "      <td>0.292756</td>\n",
       "      <td>0.288433</td>\n",
       "      <td>0.284145</td>\n",
       "      <td>0.279857</td>\n",
       "      <td>0.275569</td>\n",
       "      <td>0.271280</td>\n",
       "      <td>0.266992</td>\n",
       "      <td>0.262704</td>\n",
       "      <td>0.258416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.012666</td>\n",
       "      <td>1.016949</td>\n",
       "      <td>1.053194</td>\n",
       "      <td>1.097599</td>\n",
       "      <td>1.143640</td>\n",
       "      <td>1.192369</td>\n",
       "      <td>1.238880</td>\n",
       "      <td>1.283688</td>\n",
       "      <td>1.324305</td>\n",
       "      <td>1.363552</td>\n",
       "      <td>...</td>\n",
       "      <td>0.475822</td>\n",
       "      <td>0.467301</td>\n",
       "      <td>0.458779</td>\n",
       "      <td>0.450518</td>\n",
       "      <td>0.444609</td>\n",
       "      <td>0.438701</td>\n",
       "      <td>0.432715</td>\n",
       "      <td>0.425247</td>\n",
       "      <td>0.417780</td>\n",
       "      <td>0.410313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           1         2         3         4         5         6         7  \\\n",
       "1   0.993774  1.017558  1.070030  1.116168  1.142078  1.134735  1.182418   \n",
       "5   1.021677  1.045410  1.120324  1.175914  1.236878  1.306676  1.387931   \n",
       "9   1.020043  1.011238  1.031122  1.048642  1.049479  1.022891  1.035862   \n",
       "13  1.035248  1.014189  1.133178  1.135622  1.157984  1.213088  1.281406   \n",
       "17  1.012666  1.016949  1.053194  1.097599  1.143640  1.192369  1.238880   \n",
       "\n",
       "           8         9        10  ...       492       493       494       495  \\\n",
       "1   1.272310  1.356565  1.438978  ...  0.391775  0.384359  0.376942  0.369526   \n",
       "5   1.477973  1.549873  1.615840  ...  0.172933  0.171653  0.169739  0.167366   \n",
       "9   1.079177  1.114531  1.147282  ...  5.658505  5.625406  5.592308  5.559209   \n",
       "13  1.359858  1.423234  1.481680  ...  0.297238  0.292756  0.288433  0.284145   \n",
       "17  1.283688  1.324305  1.363552  ...  0.475822  0.467301  0.458779  0.450518   \n",
       "\n",
       "         496       497       498       499       500       501  \n",
       "1   0.362109  0.356669  0.351595  0.346521  0.341447  0.336374  \n",
       "5   0.164993  0.162620  0.160247  0.157874  0.155501  0.153128  \n",
       "9   5.526111  5.493012  5.459914  5.426815  5.393717  5.360619  \n",
       "13  0.279857  0.275569  0.271280  0.266992  0.262704  0.258416  \n",
       "17  0.444609  0.438701  0.432715  0.425247  0.417780  0.410313  \n",
       "\n",
       "[5 rows x 501 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfInfected = df[df.index % 4 == 1]\n",
    "dfInfected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "      <th>500</th>\n",
       "      <th>501</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017741</td>\n",
       "      <td>0.036585</td>\n",
       "      <td>0.054735</td>\n",
       "      <td>0.074266</td>\n",
       "      <td>0.096065</td>\n",
       "      <td>0.117691</td>\n",
       "      <td>0.139184</td>\n",
       "      <td>0.163615</td>\n",
       "      <td>0.189006</td>\n",
       "      <td>...</td>\n",
       "      <td>97.247764</td>\n",
       "      <td>96.062916</td>\n",
       "      <td>94.878068</td>\n",
       "      <td>93.693219</td>\n",
       "      <td>92.508371</td>\n",
       "      <td>92.617122</td>\n",
       "      <td>92.965783</td>\n",
       "      <td>93.314443</td>\n",
       "      <td>93.663103</td>\n",
       "      <td>94.011764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017909</td>\n",
       "      <td>0.035748</td>\n",
       "      <td>0.056118</td>\n",
       "      <td>0.076620</td>\n",
       "      <td>0.097338</td>\n",
       "      <td>0.119592</td>\n",
       "      <td>0.143024</td>\n",
       "      <td>0.171253</td>\n",
       "      <td>0.201050</td>\n",
       "      <td>...</td>\n",
       "      <td>96.481711</td>\n",
       "      <td>97.126839</td>\n",
       "      <td>97.050590</td>\n",
       "      <td>96.452872</td>\n",
       "      <td>95.855153</td>\n",
       "      <td>95.257435</td>\n",
       "      <td>94.659716</td>\n",
       "      <td>94.061998</td>\n",
       "      <td>93.464279</td>\n",
       "      <td>92.866561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016990</td>\n",
       "      <td>0.034644</td>\n",
       "      <td>0.052866</td>\n",
       "      <td>0.071444</td>\n",
       "      <td>0.090609</td>\n",
       "      <td>0.108733</td>\n",
       "      <td>0.126058</td>\n",
       "      <td>0.142408</td>\n",
       "      <td>0.158437</td>\n",
       "      <td>...</td>\n",
       "      <td>45.237808</td>\n",
       "      <td>45.424013</td>\n",
       "      <td>45.610219</td>\n",
       "      <td>45.796424</td>\n",
       "      <td>45.982629</td>\n",
       "      <td>46.168835</td>\n",
       "      <td>46.355040</td>\n",
       "      <td>46.541246</td>\n",
       "      <td>46.727451</td>\n",
       "      <td>46.913657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017002</td>\n",
       "      <td>0.036315</td>\n",
       "      <td>0.057484</td>\n",
       "      <td>0.078381</td>\n",
       "      <td>0.098831</td>\n",
       "      <td>0.119563</td>\n",
       "      <td>0.140509</td>\n",
       "      <td>0.166486</td>\n",
       "      <td>0.194109</td>\n",
       "      <td>...</td>\n",
       "      <td>92.875601</td>\n",
       "      <td>92.371850</td>\n",
       "      <td>92.874094</td>\n",
       "      <td>93.598211</td>\n",
       "      <td>94.322327</td>\n",
       "      <td>95.046444</td>\n",
       "      <td>95.770560</td>\n",
       "      <td>96.494677</td>\n",
       "      <td>97.218794</td>\n",
       "      <td>97.942910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017589</td>\n",
       "      <td>0.037434</td>\n",
       "      <td>0.056572</td>\n",
       "      <td>0.076275</td>\n",
       "      <td>0.096907</td>\n",
       "      <td>0.116533</td>\n",
       "      <td>0.135387</td>\n",
       "      <td>0.157592</td>\n",
       "      <td>0.180893</td>\n",
       "      <td>...</td>\n",
       "      <td>93.437562</td>\n",
       "      <td>93.064191</td>\n",
       "      <td>92.690821</td>\n",
       "      <td>92.516054</td>\n",
       "      <td>94.132580</td>\n",
       "      <td>95.749106</td>\n",
       "      <td>97.237129</td>\n",
       "      <td>96.278611</td>\n",
       "      <td>95.320093</td>\n",
       "      <td>94.361575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      1         2         3         4         5         6         7         8  \\\n",
       "2   0.0  0.017741  0.036585  0.054735  0.074266  0.096065  0.117691  0.139184   \n",
       "6   0.0  0.017909  0.035748  0.056118  0.076620  0.097338  0.119592  0.143024   \n",
       "10  0.0  0.016990  0.034644  0.052866  0.071444  0.090609  0.108733  0.126058   \n",
       "14  0.0  0.017002  0.036315  0.057484  0.078381  0.098831  0.119563  0.140509   \n",
       "18  0.0  0.017589  0.037434  0.056572  0.076275  0.096907  0.116533  0.135387   \n",
       "\n",
       "           9        10  ...        492        493        494        495  \\\n",
       "2   0.163615  0.189006  ...  97.247764  96.062916  94.878068  93.693219   \n",
       "6   0.171253  0.201050  ...  96.481711  97.126839  97.050590  96.452872   \n",
       "10  0.142408  0.158437  ...  45.237808  45.424013  45.610219  45.796424   \n",
       "14  0.166486  0.194109  ...  92.875601  92.371850  92.874094  93.598211   \n",
       "18  0.157592  0.180893  ...  93.437562  93.064191  92.690821  92.516054   \n",
       "\n",
       "          496        497        498        499        500        501  \n",
       "2   92.508371  92.617122  92.965783  93.314443  93.663103  94.011764  \n",
       "6   95.855153  95.257435  94.659716  94.061998  93.464279  92.866561  \n",
       "10  45.982629  46.168835  46.355040  46.541246  46.727451  46.913657  \n",
       "14  94.322327  95.046444  95.770560  96.494677  97.218794  97.942910  \n",
       "18  94.132580  95.749106  97.237129  96.278611  95.320093  94.361575  \n",
       "\n",
       "[5 rows x 501 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfRecovered = df[df.index % 4 == 2]\n",
    "dfRecovered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "      <th>500</th>\n",
       "      <th>501</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>0.000562</td>\n",
       "      <td>0.000757</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>0.001160</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>0.001635</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>...</td>\n",
       "      <td>0.947347</td>\n",
       "      <td>0.950713</td>\n",
       "      <td>0.954079</td>\n",
       "      <td>0.957445</td>\n",
       "      <td>0.960811</td>\n",
       "      <td>0.959320</td>\n",
       "      <td>0.956929</td>\n",
       "      <td>0.954537</td>\n",
       "      <td>0.952146</td>\n",
       "      <td>0.949755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>0.000763</td>\n",
       "      <td>0.000968</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.001719</td>\n",
       "      <td>0.002004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.989016</td>\n",
       "      <td>0.987952</td>\n",
       "      <td>0.986532</td>\n",
       "      <td>0.984855</td>\n",
       "      <td>0.983178</td>\n",
       "      <td>0.981502</td>\n",
       "      <td>0.979825</td>\n",
       "      <td>0.978148</td>\n",
       "      <td>0.976471</td>\n",
       "      <td>0.974794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>0.000927</td>\n",
       "      <td>0.001126</td>\n",
       "      <td>0.001324</td>\n",
       "      <td>0.001488</td>\n",
       "      <td>0.001642</td>\n",
       "      <td>...</td>\n",
       "      <td>0.454590</td>\n",
       "      <td>0.455255</td>\n",
       "      <td>0.455920</td>\n",
       "      <td>0.456585</td>\n",
       "      <td>0.457250</td>\n",
       "      <td>0.457914</td>\n",
       "      <td>0.458579</td>\n",
       "      <td>0.459244</td>\n",
       "      <td>0.459909</td>\n",
       "      <td>0.460574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>0.000774</td>\n",
       "      <td>0.001003</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.001575</td>\n",
       "      <td>0.001822</td>\n",
       "      <td>...</td>\n",
       "      <td>0.951079</td>\n",
       "      <td>0.954145</td>\n",
       "      <td>0.954334</td>\n",
       "      <td>0.953888</td>\n",
       "      <td>0.953443</td>\n",
       "      <td>0.952997</td>\n",
       "      <td>0.952552</td>\n",
       "      <td>0.952106</td>\n",
       "      <td>0.951661</td>\n",
       "      <td>0.951215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.000740</td>\n",
       "      <td>0.000931</td>\n",
       "      <td>0.001138</td>\n",
       "      <td>0.001359</td>\n",
       "      <td>0.001574</td>\n",
       "      <td>0.001787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.975329</td>\n",
       "      <td>0.959467</td>\n",
       "      <td>0.943605</td>\n",
       "      <td>0.929243</td>\n",
       "      <td>0.928406</td>\n",
       "      <td>0.927568</td>\n",
       "      <td>0.927127</td>\n",
       "      <td>0.934226</td>\n",
       "      <td>0.941326</td>\n",
       "      <td>0.948426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      1         2         3         4         5         6         7         8  \\\n",
       "3   0.0  0.000178  0.000364  0.000562  0.000757  0.000947  0.001160  0.001389   \n",
       "7   0.0  0.000175  0.000351  0.000558  0.000763  0.000968  0.001196  0.001443   \n",
       "11  0.0  0.000171  0.000352  0.000538  0.000729  0.000927  0.001126  0.001324   \n",
       "15  0.0  0.000181  0.000364  0.000563  0.000774  0.001003  0.001192  0.001351   \n",
       "19  0.0  0.000180  0.000358  0.000550  0.000740  0.000931  0.001138  0.001359   \n",
       "\n",
       "           9        10  ...       492       493       494       495       496  \\\n",
       "3   0.001635  0.001887  ...  0.947347  0.950713  0.954079  0.957445  0.960811   \n",
       "7   0.001719  0.002004  ...  0.989016  0.987952  0.986532  0.984855  0.983178   \n",
       "11  0.001488  0.001642  ...  0.454590  0.455255  0.455920  0.456585  0.457250   \n",
       "15  0.001575  0.001822  ...  0.951079  0.954145  0.954334  0.953888  0.953443   \n",
       "19  0.001574  0.001787  ...  0.975329  0.959467  0.943605  0.929243  0.928406   \n",
       "\n",
       "         497       498       499       500       501  \n",
       "3   0.959320  0.956929  0.954537  0.952146  0.949755  \n",
       "7   0.981502  0.979825  0.978148  0.976471  0.974794  \n",
       "11  0.457914  0.458579  0.459244  0.459909  0.460574  \n",
       "15  0.952997  0.952552  0.952106  0.951661  0.951215  \n",
       "19  0.927568  0.927127  0.934226  0.941326  0.948426  \n",
       "\n",
       "[5 rows x 501 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfDead = df[df.index % 4 == 3]\n",
    "dfDead.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below a plot of three infection time series for the three first outbreaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.7035320395393\n",
      "143 33.9124768491609\n",
      "35.9719802979143\n",
      "0.351581606839808\n"
     ]
    }
   ],
   "source": [
    "print(dfSusceptible.loc[0][np.argmax(dfInfected.loc[1])])\n",
    "print(np.argmax(dfInfected.loc[1]), dfInfected.loc[1][np.argmax(dfInfected.loc[1])])\n",
    "print(dfRecovered.loc[2][np.argmax(dfInfected.loc[1])])\n",
    "print(dfDead.loc[3][np.argmax(dfInfected.loc[1])])\n",
    "# dfInfected.loc[1,:].plot()\n",
    "# dfInfected.loc[5,:].plot()\n",
    "# dfInfected.loc[9,:].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert pandas to np\n",
    "npInfected = dfInfected.to_numpy()\n",
    "npSusceptible = dfSusceptible.to_numpy()\n",
    "npRecovered = dfRecovered.to_numpy()\n",
    "npDead = dfDead.to_numpy()\n",
    "\n",
    "# Find height of infection for each outbreak\n",
    "argmax = np.argmax(npInfected,axis=1)\n",
    "\n",
    "# Get the quickest rise\n",
    "amin = np.amin(np.argmax(npInfected,axis=1))\n",
    "\n",
    "# Calculate \"center\" using difference between num days to quickest rise and each outbreak's peak\n",
    "centered = -1*(argmax - amin)\n",
    "\n",
    "# Shift each outbreak to the left (and around) so the peak days are aligned to the beginning of the matrix\n",
    "npInfectedShifted = np.zeros(npInfected.shape)\n",
    "npSusceptibleShifted = np.zeros(npInfected.shape)\n",
    "npRecoveredShifted = np.zeros(npInfected.shape)\n",
    "npDeadShifted = np.zeros(npInfected.shape)\n",
    "\n",
    "for row in range(shifted.shape[0]):\n",
    "    # Get num spaces to roll by for each of the matrices\n",
    "    centeredrow = centered[row]\n",
    "    \n",
    "    thisrow = npInfected[row,:]\n",
    "    npInfectedShifted[row,:] = np.roll(thisrow,centeredrow)\n",
    "    \n",
    "    thisrow = npSusceptible[row,:]\n",
    "    npSusceptibleShifted[row,:] = np.roll(thisrow, centeredrow)\n",
    "    \n",
    "    thisrow = npRecovered[row,:]\n",
    "    npRecoveredShifted[row,:] = np.roll(thisrow, centeredrow)\n",
    "    \n",
    "    thisrow = npDead[row,:]\n",
    "    npDeadShifted[row,:] = np.roll(thisrow, centeredrow)\n",
    "    \n",
    "# print(centered)\n",
    "\n",
    "# print(npInfected[9,0])\n",
    "# print(npInfectedShifted[9,-17])\n",
    "\n",
    "# print(npSusceptible[9,0])\n",
    "# print(npSusceptibleShifted[9,-17])\n",
    "\n",
    "# print(npRecovered[9,0])\n",
    "# print(npRecoveredShifted[9,-17])\n",
    "\n",
    "# print(npDead[9,0])\n",
    "# print(npDeadShifted[9,-17])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a 90% / 10% of data for training / testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfInfected_arr = npInfectedShifted#dfInfected.values\n",
    "dfInfected_arr.shape\n",
    "TRAIN_SPLIT = int(dfInfected_arr.shape[0]-dfInfected_arr.shape[0]*0.1)\n",
    "TRAIN_SPLIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We standardize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Univariate data shape\n",
      "(150, 501)\n"
     ]
    }
   ],
   "source": [
    "uni_train_mean = dfInfected_arr[:TRAIN_SPLIT].mean()\n",
    "uni_train_std = dfInfected_arr[:TRAIN_SPLIT].std()\n",
    "uni_data = (dfInfected_arr-uni_train_mean)/uni_train_std\n",
    "print ('\\n Univariate data shape')\n",
    "print(uni_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the data into time series of `univariate_past_history=20` days length and predict the future of the current day, i.e., `univariate_future_target=0`, for the \"infected\" variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def univariate_data(dataset, start_series, end_series, history_size, target_size):\n",
    "    data = []\n",
    "    labels = []\n",
    "    start_index = history_size\n",
    "    end_index = len(dataset[0]) - target_size   \n",
    "    for c in range(start_series, end_series):\n",
    "        for i in range(start_index, end_index):\n",
    "            indices = range(i-history_size, i)\n",
    "            # Reshape data from (history_size,) to (history_size, 1)\n",
    "            data.append(np.reshape(dataset[c][indices], (history_size, 1)))\n",
    "            labels.append(dataset[c][i+target_size])\n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate_past_history = 20 #days\n",
    "univariate_future_target = 0 #current day\n",
    "\n",
    "x_train_uni, y_train_uni = univariate_data(uni_data, 0, TRAIN_SPLIT,\n",
    "                                           univariate_past_history,\n",
    "                                           univariate_future_target)\n",
    "x_val_uni, y_val_uni = univariate_data(uni_data, TRAIN_SPLIT, len(uni_data),\n",
    "                                       univariate_past_history,\n",
    "                                       univariate_future_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single window of past history\n",
      "[[-0.2478082 ]\n",
      " [-0.22484622]\n",
      " [-0.20188425]\n",
      " [-0.17892228]\n",
      " [-0.1559603 ]\n",
      " [-0.13299833]\n",
      " [-0.11003636]\n",
      " [-0.0801657 ]\n",
      " [-0.04866735]\n",
      " [-0.017169  ]\n",
      " [ 0.01432935]\n",
      " [ 0.04582769]\n",
      " [ 0.07732604]\n",
      " [ 0.10882439]\n",
      " [ 0.14032274]\n",
      " [ 0.172603  ]\n",
      " [ 0.20579935]\n",
      " [ 0.2389957 ]\n",
      " [ 0.27219205]\n",
      " [ 0.3053884 ]]\n",
      "\n",
      " Target number to predict\n",
      "0.33858475007280786\n",
      "\n",
      " Number of traing data points\n",
      "64935\n",
      "\n",
      " Number of test data points\n",
      "7215\n"
     ]
    }
   ],
   "source": [
    "print ('Single window of past history')\n",
    "print (x_train_uni[0])\n",
    "print ('\\n Target number to predict')\n",
    "print (y_train_uni[0])\n",
    "print ('\\n Number of traing data points')\n",
    "print (y_train_uni.shape[0])\n",
    "print ('\\n Number of test data points')\n",
    "print (x_val_uni.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_time_steps(length):\n",
    "    return list(range(-length, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_plot(plot_data, delta, title):\n",
    "    labels = ['History', 'True Future', 'Model Prediction']\n",
    "    marker = ['.-', 'rx', 'go']\n",
    "    time_steps = create_time_steps(plot_data[0].shape[0])\n",
    "    if delta:\n",
    "        future = delta\n",
    "    else:\n",
    "        future = 0\n",
    "    plt.title(title)\n",
    "    for i, x in enumerate(plot_data):\n",
    "        if i:\n",
    "            plt.plot(future, plot_data[i], marker[i], markersize=10,label=labels[i])\n",
    "        else:\n",
    "            plt.plot(time_steps, plot_data[i].flatten(), marker[i], label=labels[i])\n",
    "    plt.legend()\n",
    "    plt.xlim([time_steps[0], (future+5)*2])\n",
    "    plt.xlabel('Time-Step')\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'matplotlib.pyplot' from '/Library/www/anaconda3/lib/python3.7/site-packages/matplotlib/pyplot.py'>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_plot([x_train_uni[0], y_train_uni[0]], 0, 'Sample Example')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicts the mean of the `history`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline(history):\n",
    "    return np.mean(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'matplotlib.pyplot' from '/Library/www/anaconda3/lib/python3.7/site-packages/matplotlib/pyplot.py'>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_plot([x_train_uni[0], y_train_uni[0], baseline(x_train_uni[0])], 0, 'Baseline Prediction Example')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate LSTM based forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64935, 20, 1)\n",
      "(64935,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (x_train_uni.shape)\n",
    "print (y_train_uni.shape)\n",
    "x_train_uni.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batching and resampling; the dataset is repeated indefinitely. Check the tutorial for the details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<RepeatDataset shapes: ((None, 20, 1), (None,)), types: (tf.float64, tf.float64)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 256\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "train_univariate = tf.data.Dataset.from_tensor_slices((x_train_uni, y_train_uni))\n",
    "train_univariate = train_univariate.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "\n",
    "val_univariate = tf.data.Dataset.from_tensor_slices((x_val_uni, y_val_uni))\n",
    "val_univariate = val_univariate.batch(BATCH_SIZE).repeat()\n",
    "\n",
    "train_univariate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the first LSTM model with 8 units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_lstm_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.LSTM(8)#, input_shape=x_train_uni.shape[-2:])\n",
    "#     tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "simple_lstm_model.compile(optimizer='adam', loss='mae')\n",
    "# simple_lstm_model.summary()\n",
    "# x_train_uni.shape[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_8 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "in user code:\n\n    /Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1462 predict_function  *\n        return step_function(self, iterator)\n    /Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1452 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1445 run_step  **\n        outputs = model.predict_step(data)\n    /Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1418 predict_step\n        return self(x, training=False)\n    /Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py:386 call\n        outputs = layer(inputs, **kwargs)\n    /Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/recurrent.py:659 __call__\n        return super(RNN, self).__call__(inputs, **kwargs)\n    /Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/recurrent_v2.py:1108 call\n        inputs, initial_state, _ = self._process_inputs(inputs, initial_state, None)\n    /Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/recurrent.py:858 _process_inputs\n        initial_state = self.get_initial_state(inputs)\n    /Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/recurrent.py:642 get_initial_state\n        inputs=None, batch_size=batch_size, dtype=dtype)\n    /Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/recurrent.py:2520 get_initial_state\n        self, inputs, batch_size, dtype))\n    /Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/recurrent.py:2964 _generate_zero_filled_state_for_cell\n        return _generate_zero_filled_state(batch_size, cell.state_size, dtype)\n    /Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/recurrent.py:2980 _generate_zero_filled_state\n        return nest.map_structure(create_zeros, state_size)\n    /Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/nest.py:635 map_structure\n        structure[0], [func(*x) for x in entries],\n    /Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/nest.py:635 <listcomp>\n        structure[0], [func(*x) for x in entries],\n    /Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/recurrent.py:2977 create_zeros\n        return array_ops.zeros(init_state_size, dtype=dtype)\n    /Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:2747 wrapped\n        tensor = fun(*args, **kwargs)\n    /Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:2794 zeros\n        output = _constant_if_small(zero, shape, dtype, name)\n    /Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:2732 _constant_if_small\n        if np.prod(shape) < 1000:\n    <__array_function__ internals>:6 prod\n        \n    /Library/www/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3031 prod\n        keepdims=keepdims, initial=initial, where=where)\n    /Library/www/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:87 _wrapreduction\n        return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n    /Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:848 __array__\n        \" a NumPy call, which is not supported\".format(self.name))\n\n    NotImplementedError: Cannot convert a symbolic Tensor (sequential_8/lstm_8/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-41a8a0b63eab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_univariate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimple_lstm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m    129\u001b[0m           method.__name__))\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[0;32m/Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1597\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    696\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 697\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: in user code:\n\n    /Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1462 predict_function  *\n        return step_function(self, iterator)\n    /Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1452 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1445 run_step  **\n        outputs = model.predict_step(data)\n    /Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1418 predict_step\n        return self(x, training=False)\n    /Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py:386 call\n        outputs = layer(inputs, **kwargs)\n    /Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/recurrent.py:659 __call__\n        return super(RNN, self).__call__(inputs, **kwargs)\n    /Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/recurrent_v2.py:1108 call\n        inputs, initial_state, _ = self._process_inputs(inputs, initial_state, None)\n    /Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/recurrent.py:858 _process_inputs\n        initial_state = self.get_initial_state(inputs)\n    /Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/recurrent.py:642 get_initial_state\n        inputs=None, batch_size=batch_size, dtype=dtype)\n    /Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/recurrent.py:2520 get_initial_state\n        self, inputs, batch_size, dtype))\n    /Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/recurrent.py:2964 _generate_zero_filled_state_for_cell\n        return _generate_zero_filled_state(batch_size, cell.state_size, dtype)\n    /Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/recurrent.py:2980 _generate_zero_filled_state\n        return nest.map_structure(create_zeros, state_size)\n    /Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/nest.py:635 map_structure\n        structure[0], [func(*x) for x in entries],\n    /Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/nest.py:635 <listcomp>\n        structure[0], [func(*x) for x in entries],\n    /Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/recurrent.py:2977 create_zeros\n        return array_ops.zeros(init_state_size, dtype=dtype)\n    /Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:2747 wrapped\n        tensor = fun(*args, **kwargs)\n    /Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:2794 zeros\n        output = _constant_if_small(zero, shape, dtype, name)\n    /Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:2732 _constant_if_small\n        if np.prod(shape) < 1000:\n    <__array_function__ internals>:6 prod\n        \n    /Library/www/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3031 prod\n        keepdims=keepdims, initial=initial, where=where)\n    /Library/www/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:87 _wrapreduction\n        return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n    /Library/www/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:848 __array__\n        \" a NumPy call, which is not supported\".format(self.name))\n\n    NotImplementedError: Cannot convert a symbolic Tensor (sequential_8/lstm_8/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported\n"
     ]
    }
   ],
   "source": [
    "for x, y in val_univariate.take(1):\n",
    "    print(simple_lstm_model.predict(x).shape)\n",
    "    print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When passing an indefinitely repeated training data set, we need to specify the numbre of steps per training interval (epoch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVALUATION_INTERVAL = 2000\n",
    "EPOCHS = 10\n",
    "\n",
    "simple_lstm_model.fit(train_univariate, \n",
    "                      epochs=EPOCHS,\n",
    "                      steps_per_epoch=EVALUATION_INTERVAL,\n",
    "                      validation_data=val_univariate, \n",
    "                      validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for x, y in val_univariate.take(3):\n",
    "    plot = show_plot([x[0].numpy(), y[0].numpy(), simple_lstm_model.predict(x)[0]], 0, 'Simple LSTM model')\n",
    "    plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate LSTM based forecasting - Single Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use three variables \"Infected\", \"Recovered\", and \"Deceased\", to forcast \"Infected\" at one single day in the future.\n",
    "\n",
    "Here a plot of the time series of the three variables for one outbreak. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfInfected.loc[1,:].plot()\n",
    "dfRecovered.loc[2,:].plot()\n",
    "dfDead.loc[3,:].plot()\n",
    "dfInfected = dfInfected.values\n",
    "dfRecovered_arr = dfRecovered.values\n",
    "dfDead_arr = dfDead.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We prepare the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#as before\n",
    "dfInfected_train_mean = dfInfected_arr[:TRAIN_SPLIT].mean()\n",
    "dfInfected_train_std = dfInfected_arr[:TRAIN_SPLIT].std()\n",
    "dfInfected_data = (dfInfected_arr-dfInfected_train_mean)/dfInfected_train_std\n",
    "#for Recovered\n",
    "dfRecovered_train_mean = dfRecovered_arr[:TRAIN_SPLIT].mean()\n",
    "dfRecovered_train_std = dfRecovered_arr[:TRAIN_SPLIT].std()\n",
    "dfRecovered_data = (dfRecovered_arr-dfRecovered_train_mean)/dfRecovered_train_std\n",
    "#for Dead\n",
    "dfDead_train_mean = dfDead_arr[:TRAIN_SPLIT].mean()\n",
    "dfDead_train_std = dfDead_arr[:TRAIN_SPLIT].std()\n",
    "dfDead_data = (dfDead_arr-dfDead_train_mean)/dfDead_train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.array([dfInfected_data, dfRecovered_data, dfDead_data])\n",
    "dataset.shape\n",
    "print ('\\n Multivariate data shape')\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivariate_data(dataset, target, start_series, end_series, history_size,\n",
    "                      target_size, step, single_step=False):\n",
    "    data = []\n",
    "    labels = []\n",
    "    start_index = history_size\n",
    "    end_index = len(dataset[0][0]) - target_size   \n",
    "    for c in range(start_series, end_series):\n",
    "        for i in range(start_index, end_index):\n",
    "            indices = range(i-history_size, i, step)\n",
    "            one = dataset[0][c][indices]\n",
    "            two = dataset[1][c][indices]\n",
    "            three = dataset[2][c][indices]\n",
    "            data.append(np.transpose(np.array([one, two, three])))\n",
    "            \n",
    "            if single_step:\n",
    "                labels.append(target[c][i+target_size])\n",
    "            else:\n",
    "                labels.append(np.transpose(target[c][i:i+target_size]))\n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get training and valdation data for time series with a `past_history = 20` days for every other day (`STEP = 2`) and want to predict the \"Infected\" five days ahead (`future_target = 5`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_history = 20\n",
    "future_target = 5\n",
    "STEP = 2\n",
    "\n",
    "x_train_single, y_train_single = multivariate_data(dataset, dfInfected_data, 0, TRAIN_SPLIT, \n",
    "                                                   past_history, future_target, STEP,\n",
    "                                                   single_step=True)\n",
    "x_val_single, y_val_single = multivariate_data(dataset, dfInfected_data, TRAIN_SPLIT, dataset.shape[1], \n",
    "                                               past_history, future_target, STEP,\n",
    "                                               single_step=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print ('Single window of past history : {}'.format(x_train_single[0].shape))\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, batching and resampling; the dataset is repeated indefinitely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_single = tf.data.Dataset.from_tensor_slices((x_train_single, y_train_single))\n",
    "train_data_single = train_data_single.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "\n",
    "val_data_single = tf.data.Dataset.from_tensor_slices((x_val_single, y_val_single))\n",
    "val_data_single = val_data_single.batch(BATCH_SIZE).repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_step_model = tf.keras.models.Sequential()\n",
    "single_step_model.add(tf.keras.layers.LSTM(32, input_shape=x_train_single.shape[-2:]))\n",
    "single_step_model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "single_step_model.compile(optimizer=tf.keras.optimizers.RMSprop(), loss='mae')\n",
    "single_step_model.summary()\n",
    "x_train_single.shape[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in val_data_single.take(1):\n",
    "    print(single_step_model.predict(x).shape)\n",
    "print ('\\n Number of traing data points')\n",
    "print (x_train_single.shape[0])\n",
    "print ('\\n Number of test data points')\n",
    "print (x_val_single.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_step_history = single_step_model.fit(train_data_single, epochs=EPOCHS,\n",
    "                                            steps_per_epoch=EVALUATION_INTERVAL,\n",
    "                                            validation_data=val_data_single,\n",
    "                                            validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_history(history, title):\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(len(loss))\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train_history(single_step_history,'Single Step Training and validation loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in val_data_single.take(3):\n",
    "    plot = show_plot([x[0][:, 0].numpy(), y[0].numpy(),\n",
    "                    single_step_model.predict(x)[0]], future_target,\n",
    "                   'Single Step Prediction')\n",
    "    plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate LSTM - Multiple Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still, we use a series of observed values of the three variables \"Infected\", \"Recovered\", and \"Deceased\" (`past_history = 40, STEP =2`), but now to forcast the \"Infected\" values for a series day in the future (`future_target = 10`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_history = 40\n",
    "future_target = 10\n",
    "STEP =2\n",
    "x_train_multi, y_train_multi = multivariate_data(dataset, dfInfected_data, 0, TRAIN_SPLIT, \n",
    "                                                    past_history, future_target, STEP)\n",
    "x_val_multi, y_val_multi = multivariate_data(dataset, dfInfected_data, TRAIN_SPLIT, dataset.shape[1], \n",
    "                                                past_history, future_target, STEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print ('Single window of past history : {}'.format(x_train_multi[0].shape))\n",
    "print ('\\nTarget window to predict : {}'.format(y_train_multi[0].shape))\n",
    "print ('\\nNumber of traing data points: {}'.format(x_train_multi.shape[0]))\n",
    "print ('\\nNumber of test data points: {}'.format(x_val_multi.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, batching and resampling; the dataset is repeated indefinitely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_multi = tf.data.Dataset.from_tensor_slices((x_train_multi, y_train_multi))\n",
    "train_data_multi = train_data_multi.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "\n",
    "val_data_multi = tf.data.Dataset.from_tensor_slices((x_val_multi, y_val_multi))\n",
    "val_data_multi = val_data_multi.batch(BATCH_SIZE).repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_step_plot(history, true_future, prediction):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    num_in = create_time_steps(len(history))\n",
    "    num_out = len(true_future)\n",
    "    plt.plot(num_in, np.array(history[:, 0]), label='History')\n",
    "    plt.plot(np.arange(num_out)/STEP, np.array(true_future), 'bo', label='True Future')\n",
    "    if prediction.any():\n",
    "        plt.plot(np.arange(num_out)/STEP, np.array(prediction), 'ro', label='Predicted Future')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for x, y in train_data_multi.take(1):\n",
    "    multi_step_plot(x[0], y[0], np.array([0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we bild a model with two LSTM layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_step_model = tf.keras.models.Sequential()\n",
    "multi_step_model.add(tf.keras.layers.LSTM(32,\n",
    "                                          return_sequences=True,\n",
    "                                          input_shape=x_train_multi.shape[-2:]))\n",
    "multi_step_model.add(tf.keras.layers.LSTM(16, activation='relu'))\n",
    "multi_step_model.add(tf.keras.layers.Dense(future_target))\n",
    "\n",
    "multi_step_model.compile(optimizer=tf.keras.optimizers.RMSprop(clipvalue=1.0), loss='mae')\n",
    "multi_step_model.summary()\n",
    "x_train_multi.shape[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in val_data_multi.take(1):\n",
    "    print (multi_step_model.predict(x).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training time is longer for this more complex model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_step_history = multi_step_model.fit(train_data_multi, epochs=EPOCHS,\n",
    "                                          steps_per_epoch=EVALUATION_INTERVAL,\n",
    "                                          validation_data=val_data_multi,\n",
    "                                          validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train_history(multi_step_history, 'Multi-Step Training and validation loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in val_data_multi.take(3):\n",
    "    multi_step_plot(x[0], y[0], multi_step_model.predict(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
